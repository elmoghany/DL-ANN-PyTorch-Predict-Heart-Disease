{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# fetch dataset \n",
    "heart_disease = fetch_ucirepo(id=45) \n",
    "\n",
    "# print(f'data: {heart_disease.data}')\n",
    "# print(f'metadata: {heart_disease.metadata}')\n",
    "# print(f'var: {heart_disease.variables}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features keys:\n",
      "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
      "       'exang', 'oldpeak', 'slope', 'ca', 'thal'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# data (as pandas dataframes) \n",
    "X = heart_disease.data.features \n",
    "y = heart_disease.data.targets \n",
    "\n",
    "y = (y['num'] >  0).astype(int)\n",
    "# print(y.values)\n",
    "# print(y.keys())\n",
    "#features\n",
    "#1 age\n",
    "#2 sex\n",
    "#3 cp\n",
    "#4 trestbps\n",
    "#5 chol\n",
    "#6 fbs\n",
    "#7 restecg\n",
    "#8 thalach\n",
    "#9 exang\n",
    "#10 oldpeak\n",
    "#11 slope\n",
    "#12 ca\n",
    "#13 thal\n",
    "print(f'features keys:\\n{X.keys()}')\n",
    "# print('###############################')\n",
    "# print('###############################')\n",
    "# print('###############################')\n",
    "# print(f'Targets num:\\n{y}')\n",
    "# we need to group them \"binarize\" into 0 & (1,2,3)=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elmog\\AppData\\Local\\Temp\\ipykernel_10604\\1549607059.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[cols2zscore] = X[cols2zscore].apply(stats.zscore)\n"
     ]
    }
   ],
   "source": [
    "# Step 0: Normalize data\n",
    "# z-score all inputs features\n",
    "cols2zscore = X.keys()\n",
    "# cols2zscore = cols2zscore.drop('col-name')\n",
    "X[cols2zscore] = X[cols2zscore].apply(stats.zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step1: Convert numpy data into tensor data\n",
    "xx = torch.tensor( X[cols2zscore].values ).float()\n",
    "yy  = torch.tensor( y.values  ).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([303, 13])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([303])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step2: use scikit learn to split the data\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(xx, yy, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Convert into PyTorch Datasets\n",
    "train_data = TensorDataset(train_data, train_labels)\n",
    "test_data  = TensorDataset(test_data , test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([272, 13])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([31, 13])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Translate into dataloader objects\n",
    "batchsize    = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batchsize, shuffle=True, drop_last=True)\n",
    "test_loader  = DataLoader(test_data,  batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Deep Learning Model\n",
    "def createTheDiseasePredNet():\n",
    "    class diseasePredictionNet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            \n",
    "            self.input = nn.Linear(2,20)\n",
    "            \n",
    "            # self.bnormHidden1 =  nn.BatchNorm1d(20)\n",
    "            self.hidden1 = nn.Linear(20,10)\n",
    "            \n",
    "            # self.bnormHidden2 =  nn.BatchNorm1d(10)\n",
    "            self.hidden2 = nn.Linear(10,5)\n",
    "            \n",
    "            self.output = nn.Linear(5,1)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            \n",
    "            x = F.leaky_relu( self.input(x) )\n",
    "            \n",
    "            # x = self.bnormHidden1(x)\n",
    "            x = F.leaky_relu( self.hidden1(x) )\n",
    "\n",
    "            # x = self.bnormHidden2(x)\n",
    "            x = F.leaky_relu( self.hidden2(x) )\n",
    "                        \n",
    "            x = self.output(x)\n",
    "            \n",
    "            return x\n",
    "        \n",
    "    diseasePredictionModel = diseasePredictionNet().to(device)\n",
    "    \n",
    "    lossfun = nn.MSELoss()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(diseasePredictionModel.parameters(), lr=0.01)#, betas=(0.9, 0.999), eps=1e-8)\n",
    "    \n",
    "    return diseasePredictionModel, lossfun, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
