{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# fetch dataset \n",
    "heart_disease = fetch_ucirepo(id=45) \n",
    "\n",
    "# print(f'data: {heart_disease.data}')\n",
    "# print(f'metadata: {heart_disease.metadata}')\n",
    "# print(f'var: {heart_disease.variables}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features keys:\n",
      "Index(['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
      "       'exang', 'oldpeak', 'slope', 'ca', 'thal'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# data (as pandas dataframes) \n",
    "X = heart_disease.data.features \n",
    "y = heart_disease.data.targets \n",
    "\n",
    "y = (y['num'] >  0).astype(int)\n",
    "# print(y.values)\n",
    "# print(y.keys())\n",
    "#features\n",
    "#1 age\n",
    "#2 sex\n",
    "#3 cp\n",
    "#4 trestbps\n",
    "#5 chol\n",
    "#6 fbs\n",
    "#7 restecg\n",
    "#8 thalach\n",
    "#9 exang\n",
    "#10 oldpeak\n",
    "#11 slope\n",
    "#12 ca\n",
    "#13 thal\n",
    "print(f'features keys:\\n{X.keys()}')\n",
    "# print('###############################')\n",
    "# print('###############################')\n",
    "# print('###############################')\n",
    "# print(f'Targets num:\\n{y}')\n",
    "# we need to group them \"binarize\" into 0 & (1,2,3)=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "#GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elmog\\AppData\\Local\\Temp\\ipykernel_10604\\1549607059.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[cols2zscore] = X[cols2zscore].apply(stats.zscore)\n"
     ]
    }
   ],
   "source": [
    "# Step 0: Normalize data\n",
    "# z-score all inputs features\n",
    "cols2zscore = X.keys()\n",
    "# cols2zscore = cols2zscore.drop('col-name')\n",
    "X[cols2zscore] = X[cols2zscore].apply(stats.zscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step1: Convert numpy data into tensor data\n",
    "xx = torch.tensor( X[cols2zscore].values ).float()\n",
    "yy  = torch.tensor( y.values  ).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([303, 13])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([303])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step2: use scikit learn to split the data\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(xx, yy, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Convert into PyTorch Datasets\n",
    "train_data = TensorDataset(train_data, train_labels)\n",
    "test_data  = TensorDataset(test_data , test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([272, 13])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([31, 13])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.tensors[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Translate into dataloader objects\n",
    "batchsize    = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batchsize, shuffle=True, drop_last=True)\n",
    "test_loader  = DataLoader(test_data,  batch_size=test_data.tensors[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Deep Learning Model\n",
    "def createTheNet():\n",
    "    class diseasePredictionNet(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "            \n",
    "            self.input = nn.Linear(2,20)\n",
    "            \n",
    "            self.bnormHidden1 =  nn.BatchNorm1d(20)\n",
    "            self.hidden1 = nn.Linear(20,10)\n",
    "            \n",
    "            self.bnormHidden2 =  nn.BatchNorm1d(10)\n",
    "            self.hidden2 = nn.Linear(10,5)\n",
    "            \n",
    "            self.output = nn.Linear(5,1)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            \n",
    "            x = F.leaky_relu( self.input(x) )\n",
    "            \n",
    "            # x = self.bnormHidden1(x)\n",
    "            x = F.leaky_relu( self.hidden1(x) )\n",
    "\n",
    "            # x = self.bnormHidden2(x)\n",
    "            x = F.leaky_relu( self.hidden2(x) )\n",
    "                        \n",
    "            x = self.output(x)\n",
    "            \n",
    "            return x\n",
    "        \n",
    "    diseasePredictionModel = diseasePredictionNet().to(device)\n",
    "    \n",
    "    lossfun = nn.BCEWithLogitsLoss()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(diseasePredictionModel.parameters(), lr=0.01)#, betas=(0.9, 0.999), eps=1e-8)\n",
    "    \n",
    "    return diseasePredictionModel, lossfun, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1846, 0.1161]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "diseasePredictionNet(\n",
       "  (input): Linear(in_features=2, out_features=20, bias=True)\n",
       "  (bnormHidden1): BatchNorm1d(20, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (hidden1): Linear(in_features=20, out_features=10, bias=True)\n",
       "  (bnormHidden2): BatchNorm1d(10, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (hidden2): Linear(in_features=10, out_features=5, bias=True)\n",
       "  (output): Linear(in_features=5, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the model that is has NO ERRORS!\n",
    "\n",
    "net2, lossfun, optimizer = createTheNet()\n",
    "\n",
    "input = torch.rand(1,2).to(device)\n",
    "net2.eval()\n",
    "net2(input)\n",
    "print(input)\n",
    "net2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Model\n",
    "\n",
    "def trainTheModel(diseasePredictionTrain, lossfun, optimizer):\n",
    "    \n",
    "    #number of epochs to train\n",
    "    numepochs = 50\n",
    "        \n",
    "    #initialize losses & accuracy\n",
    "    losses   = torch.zeros(numepochs)\n",
    "    trainAcc = []\n",
    "    testAcc  = []\n",
    "    \n",
    "    for epochi in range(numepochs):\n",
    "        \n",
    "        #batch loss & accuracy\n",
    "        batchLoss = []\n",
    "        batchAcc  = []\n",
    "        \n",
    "        #loop over mini-batches\n",
    "        for X,y in train_loader:\n",
    "            \n",
    "            # push data to GPU\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            #Forward pass & loss\n",
    "            yHat = diseasePredictionTrain(X)\n",
    "            loss = lossfun(yHat, y)\n",
    "            \n",
    "            #backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            #loss from this batch\n",
    "            batchLoss.append(loss.item())\n",
    "            \n",
    "            # accuracy from this batch for categorical data\n",
    "            # batchMathces = (torch.abs(yHat - y)).detach().cpu().float().numpy()\n",
    "            # batchAcc.append(( batchMathces < 1))\n",
    "            \n",
    "            #accuracy from this batch -> for BCE\n",
    "            matches = torch.argmax(yHat,axis=1) == y ##\n",
    "            matchesNumeric = matches.float()\n",
    "            batchAcc.append( 100*torch.mean(matchesNumeric).item() )\n",
    "        \n",
    "        #average accuracy across mini-batches\n",
    "        trainAcc.append(100 * np.mean((batchAcc)))\n",
    "        \n",
    "        #average losses across all mini-batches\n",
    "        losses[epochi] = np.mean(batchLoss)\n",
    "        \n",
    "        ################################\n",
    "        \n",
    "        #final forward pass for Test Accuracy\n",
    "        X,y = next(iter(test_loader))\n",
    "        \n",
    "        # push data to GPU\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            yHat = diseasePredictionTrain(X)\n",
    "            \n",
    "        #compute the test accuracy for categorical data\n",
    "        # testMatches = (torch.abs(yHat - y)).detach().cpu().float().numpy()\n",
    "        # testMatchesNumeric = (testMatches < 1)\n",
    "        # testAcc.append(100 * np.mean( testMatchesNumeric ) )\n",
    "\n",
    "        #compute the test accuracy for BCE\n",
    "        testMatches = torch.argmax(yHat, axis=1) == y\n",
    "        testMatchesNumeric = testMatches.float()\n",
    "        testAcc.append(100 * np.mean( testMatchesNumeric ).item() )\n",
    "    \n",
    "    return trainAcc, testAcc, losses, diseasePredictionTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'createTheNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[71], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Test the training code that it has NO ERRORS\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m diseaseModel, lossfun, optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mcreateTheNet\u001b[49m()\n\u001b[0;32m      3\u001b[0m trainAcc, testAcc, losses, diseasePredictionTrained \u001b[38;5;241m=\u001b[39m trainTheModel(diseaseModel, lossfun, optimizer)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'createTheNet' is not defined"
     ]
    }
   ],
   "source": [
    "# Test the training code that it has NO ERRORS\n",
    "diseaseModel, lossfun, optimizer = createTheNet()\n",
    "trainAcc, testAcc, losses, diseasePredictionTrained = trainTheModel(diseaseModel, lossfun, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "ax[0].plot(losses)\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_title('Model Loss')\n",
    "\n",
    "ax[1].plot(trainAcc, label='Train')\n",
    "ax[1].plot(testAcc, label='Test')\n",
    "ax[1].legend()\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].set_title(f'Test accuracy {testAcc[-1]:.2f}%')\n",
    "ax[1].set_ylim([0,110])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
